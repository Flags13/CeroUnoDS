{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los datos de fashion mnist y guárdalos en las variables correspondientes\n",
    "        = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Imprime las dimensiones de los datos de entrenamiento\n",
    "print('Datos de entrenamiento:',    )\n",
    "print('Datos de prueba:',    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_obtaining.jpg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prenda = ['T-shirt','Trouser','Pullover', 'Press','Coat','Sandal','Shirt','Sneaker','Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ver un ejemplo.\n",
    "# Aquí estamos seleccionando una imagen al azar\n",
    "sample = np.random.choice(X_train.shape[0])\n",
    "\n",
    "print('La imagen es:', prenda[y_train[sample]])\n",
    "sns.set_style('whitegrid')\n",
    "plt.imshow(X_train[sample,:,:], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para empezar, la red neuronal que hemos visto hasta ahora no acepta imágenes como datos de entrada. Para ello, tenemos que convertir las matrices que representan la imagen a vectores. Además, como queremos hacer una clasificación de más de dos categorías, hay que codificar las etiquetas con un one-hot-encoding.\n",
    "\n",
    "Esto último lo podemos hacer con pandas, scikit learn o el mismo keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte a 3 dimensiones el tamaño de las imágenes\n",
    "X_train  = \n",
    "X_test   = \n",
    "\n",
    "# Imprime el tamaño de las imágenes\n",
    "print(  )\n",
    "print(  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la forma de los datos de entrada\n",
    "input_shape = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambia la escala de los datos de entrada de 0-255 a 0-1\n",
    "X_train = \n",
    "X_test  = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiamos a one.hot encoding las variables de etiqueta. ¿Cuántas categorías diferentes hay para clasificar las imágenes?\n",
    "num_classes = \n",
    "\n",
    "# Utiliza la variable anterior para codificar los datos de etiqueta\n",
    "y_train = tf.keras.utils.to_categorical(  ,  )\n",
    "y_test  = tf.keras.utils.to_categorical(  ,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las funciones necesarias de Keras.\n",
    "# Una capa de convolución usamos Conv2D\n",
    "# Una capa de pooling (con la operación max) la usamos como MaxPooling2D\n",
    "# Para convertir el resultado de la convolución y pooling a un vector, usamos Flatten\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "# Creamos un modelo secuencial como en el ejemplo anterior\n",
    "redConv = \n",
    "\n",
    "# Agregamos una capa de 32 filtros de 3x3 con función de activación ReLu\n",
    "\n",
    "\n",
    "# Agregamos una capa de pooling de 2x2\n",
    "\n",
    "\n",
    "## Para convertir la capa anterior a un vector, usamos flatten\n",
    "\n",
    "\n",
    "## Agregamos una capa de 100 nodos con activación relu\n",
    "\n",
    "\n",
    "## Como queremos clasificar en muchas categorías, ¿cuál función de activación utilizamos?\n",
    "## El tipo de capa es Dense como en una red normal.\n",
    "\n",
    "\n",
    "## Mostrar el resumen \n",
    "redConv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entrenamos el modelo con un optimizador sgd. Ahora vamos a personalizar el optimizador\n",
    "optimizador = tensorflow.keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "# Utiliza el optimizador anterior para compilar el modelo\n",
    "redConv.compile(loss=     , optimizer=optimizador, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corre el modelo con .fit con lotes de 32 y 10 epocas\n",
    "history = redConv.fit(X_train, y_train, batch_size=  , epochs=  , validation_split=0.1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza la función evalate para ver el error y la precisión del modelo entrenado\n",
    "loss, accuracy  = redConv.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "# Graficar resultados\n",
    "sns.set()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Precisión del modelo durante entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Época')\n",
    "plt.legend(['Entrenamiento', 'Validación'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Precisión en datos de prueba: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index   = np.random.choice(X_test.shape[0])\n",
    "x_index = X_test[index,:].reshape(1,28,28,1)\n",
    "prediccion = np.squeeze(redConv.predict(x_index))\n",
    "\n",
    "# El vector de predicción contiene los valores de las probabilidades de que sea uno de los dígitos de (0,1,2,...,8,9) en ese\n",
    "# orden. Para encontrar el valor predicho hay que buscar la POSICIÓN con el valor más alto.\n",
    "max_index = np.squeeze(np.where(prediccion==prediccion.max()))\n",
    "y_index   = np.squeeze(np.where(y_test[index,:]==1))\n",
    "\n",
    "# Mostrar el resultado\n",
    "print('La imagen predicha es:', prenda[max_index], '\\n')\n",
    "print('El imagen real es:', prenda[y_index])\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.imshow(np.reshape(X_test[index,:],(28,28)), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay una opción en las capas de convolución que se llama 'padding'.\n",
    "# Esta opción rellena la imagen de tal manera que el resultado después de aplicar el filtro tiene el mismo tamaño que\n",
    "# la imagen original.\n",
    "\n",
    "# Utiliza la opción padding='same' para ver cómo mejora o empeora el modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
