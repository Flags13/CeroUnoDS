{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee la tabla 'Churn.csv' y guárdala en una variable llamada clientes\n",
    "clientes = \n",
    "\n",
    "# Muestra los primeros renglones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprime el tamaño de la tabla clientes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las columnas 'RowNumber','CustomerId','Surname' no son útiles para la predicción. \n",
    "# Guarda en una variable llamada X las columnas que sí nos pueden ayudar en la predicción columnas [3-12]\n",
    "X = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La variable que queremos predecir es 'Exited', que nos dice si un cliente dejó de comprar.\n",
    "# Guardar esta columna en una variable llamada y\n",
    "y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver el tipo de datos de cada columna numérica. Hazlo con la función X.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las columnas ['Geography', 'Gender'] son categóricas. Ve cuáles son las distintas categorías con\n",
    "# X[col].count_values() para cada columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta los categorías de la segunda columna aquí\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para convertir estas variables categóricas a numéricas vamos a utilizar pd.get_dummies()\n",
    "# Guarda el resultado en la variable X_dummy\n",
    "X_dummy = \n",
    "\n",
    "# Imprime las primeras filas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a poner todas las variables en la misma escala con StandardScaler()\n",
    "# Las columnas CreditScore,Age,Tenure,Balance,NumOfProducts y EstimatedSalary son muy grandes comparadas con las demás columnas\n",
    "# Usa StandardScaler en estas columnas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler   = StandardScaler()\n",
    "columns  = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "\n",
    "X_scaled = X_dummy.copy()\n",
    "X_scaled.loc[:, columns] = scaler.fit_transform(        )\n",
    "\n",
    "# Imprime las primeras filas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Las columnas Gender_Female,Gender_Male son complementarias. Si un renglón tiene un valor de 1 en la columna Female\n",
    "# en la columna Male el valor es 0. Entonces hay información redundante. ELimina una de estas columnas (la que quieras.)\n",
    "X_scaled = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algo similar pasa con las columnas de Geography_France,Geography_Germany, Geography_Spain. Elimina una de estas columnas\n",
    "X_scaled = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos ahora a partir la tabla para obtener el grupo de entrenamiento y el grupo de prueba.\n",
    "# Utiliza train_test_split de sklearn.model_selection\n",
    "# Los valores que vamos a partir son los de la última tabla (X_scaled)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(        , y, test_size = 0.3, random_state = 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a crear la red neuronal\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un modelo secuecial\n",
    "modelo = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega la primera capa al modelo. Recuerda que la primera capa tiene que conocer cuántas variables hay de entrada\n",
    "# (Tip: cuántas columnas tiene X_train?)\n",
    "# Usa la función de activación ReLu\n",
    "\n",
    "input_shape = \n",
    "modelo.add(       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega una o más capas más al modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrega la capa de salida. Este es un problema de clasificación. ¿Cuál es la función de activación correcta?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ve un resumen del modelo con la función .summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hay que compilar el modelo. \n",
    "# Utiliza el optimizador 'adam'. ¿Cuál es la función de costo correcta?\n",
    "# Puedes escoger entre 'mse', 'binary_crossentropy', 'categorial_crossentropy'\n",
    "modelo.compile(optimizer =     , loss =       , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a entrenar el modelo. Utiliza la variable history para guardar el progreso del modelo.\n",
    "history = modelo.fit(X_train, y_train, batch_size =      , epochs =       , verbose= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecuta la siguiente celda para ver el progreso del entrenamiento.\n",
    "\n",
    "loss, accuracy  = modelo.evaluate(X_test, y_test, verbose=False)\n",
    "# Graficar resultados\n",
    "sns.set()\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Precisión del modelo durante entrenamiento')\n",
    "plt.ylabel('Precisión')\n",
    "plt.xlabel('Época')\n",
    "# plt.legend(['Entrenamiento', 'Validación'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Precisión en datos de prueba: {accuracy:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a utilizar los datos de prueba para ver que tan bueno es el modelo\n",
    "# Usa el método predict para obtener los resultados de los datos X_tes\n",
    "prediccion = modelo.predict(      )\n",
    "\n",
    "# Ahora define un punto de corte para asignar si el cliente va a abandonar o no.\n",
    "corte =    \n",
    "\n",
    "y_pred = np.squeeze(1*(prediccion>corte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la precisión con los datos de prueba. La precisión la puedes calcular con precision_score de sklearn.metrics \n",
    "from sklearn.metrics import precision_score\n",
    "precision =   \n",
    "print('Precisión:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora veamos cómo se comparan los valores reales contra los predichos.\n",
    "pd.crosstab(y_pred, y_test, rownames=['Predicción'], colnames=['Valor Real'])\n",
    "\n",
    "# Qué pasa si cambias el punto de corte? Cambia el valor en las celdas anteriores y prueba otra vez."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
